{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR7aKlPakBccaVMLdF476u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lefaa/crimeStudy/blob/main/mergeddataxgboost.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from datetime import datetime\n",
        "\n",
        "# Load the data\n",
        "df_all = pd.read_csv('pivotedmerged.csv')\n",
        "df_all['date'] = pd.to_datetime(df_all['date'])\n",
        "\n",
        "# Only keep useful columns\n",
        "df_all = df_all.loc[:, (df_all != 0).any(axis=0)]  # remove all-zero cols\n",
        "df_all = df_all[df_all['date'].dt.year < 2023]  # keep only past for training\n",
        "\n",
        "# Define features and target (predict each country one by one)\n",
        "features = df_all.drop(columns=['date', 'AF'])  # drop target + date\n",
        "target = df_all['AF']\n",
        "\n",
        "# Train model\n",
        "dtrain = xgb.DMatrix(features, label=target)\n",
        "params = {'objective': 'reg:squarederror', 'eval_metric': 'rmse', 'max_depth': 6, 'eta': 0.1}\n",
        "model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "# Future dates to predict for (monthly)\n",
        "future_months = pd.date_range(start='2024-01-01', end='2024-12-01', freq='MS')\n",
        "\n",
        "# Use the last known features as a proxy for each future month\n",
        "# (You can improve this using rolling stats, lag features, etc.)\n",
        "last_row = features.iloc[-1]\n",
        "\n",
        "# For each month, duplicate the last row and change the date\n",
        "future_features = pd.DataFrame([last_row.values]*12, columns=features.columns)\n",
        "future_features['date'] = future_months\n",
        "\n",
        "# Predict for each country\n",
        "countries = [col for col in df_all.columns if col not in ['date']]  # get all countries\n",
        "\n",
        "all_preds = []\n",
        "\n",
        "for country in countries:\n",
        "    y_train = df_all[country]\n",
        "    dtrain = xgb.DMatrix(features, label=y_train)\n",
        "    model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "    df_future = future_features.copy()\n",
        "    df_future.drop(columns=['date'], inplace=True)\n",
        "    df_future_dm = xgb.DMatrix(df_future)\n",
        "\n",
        "    preds = model.predict(df_future_dm)\n",
        "    df_result = pd.DataFrame({\n",
        "        'date': future_months,\n",
        "        'country': country,\n",
        "        'prediction': preds\n",
        "    })\n",
        "    all_preds.append(df_result)\n",
        "\n",
        "# Concatenate and save\n",
        "df_final = pd.concat(all_preds, ignore_index=True)\n",
        "df_final.to_csv(\"timeseries_predictions.csv\", index=False)\n",
        "print(\"Predictions saved to timeseries_predictions.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Zs8EEOM2qzc",
        "outputId": "06b18628-b850-4221-8d83-5911c3cd1b08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predictions saved to timeseries_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FwLLmq_wZRPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d492785e-febd-42f8-9173-a24aa3634d36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Training for AA...\n",
            "Training for AC...\n",
            "Training for AE...\n",
            "Training for AF...\n",
            "Training for AG...\n",
            "Training for AJ...\n",
            "Training for AL...\n",
            "Training for AM...\n",
            "Training for AN...\n",
            "Training for AO...\n",
            "Training for AQ...\n",
            "Training for AR...\n",
            "Training for AS...\n",
            "Training for AU...\n",
            "Training for AV...\n",
            "Training for AY...\n",
            "Training for BA...\n",
            "Training for BB...\n",
            "Training for BC...\n",
            "Training for BD...\n",
            "Training for BE...\n",
            "Training for BF...\n",
            "Training for BG...\n",
            "Training for BH...\n",
            "Training for BK...\n",
            "Training for BL...\n",
            "Training for BM...\n",
            "Training for BN...\n",
            "Training for BO...\n",
            "Training for BP...\n",
            "Training for BQ...\n",
            "Training for BR...\n",
            "Training for BT...\n",
            "Training for BU...\n",
            "Training for BX...\n",
            "Training for BY...\n",
            "Training for CA...\n",
            "Training for CB...\n",
            "Training for CD...\n",
            "Training for CE...\n",
            "Training for CF...\n",
            "Training for CG...\n",
            "Training for CH...\n",
            "Training for CI...\n",
            "Training for CJ...\n",
            "Training for CM...\n",
            "Training for CN...\n",
            "Training for CO...\n",
            "Training for CQ...\n",
            "Training for CS...\n",
            "Training for CT...\n",
            "Training for CU...\n",
            "Training for CV...\n",
            "Training for CW...\n",
            "Training for CY...\n",
            "Training for DA...\n",
            "Training for DJ...\n",
            "Training for DO...\n",
            "Training for DQ...\n",
            "Training for DR...\n",
            "Training for EC...\n",
            "Training for EG...\n",
            "Training for EI...\n",
            "Training for EK...\n",
            "Training for EN...\n",
            "Training for ER...\n",
            "Training for ES...\n",
            "Training for ET...\n",
            "Training for EU...\n",
            "Training for EZ...\n",
            "Training for FG...\n",
            "Training for FI...\n",
            "Training for FJ...\n",
            "Training for FK...\n",
            "Training for FM...\n",
            "Training for FO...\n",
            "Training for FP...\n",
            "Training for FR...\n",
            "Training for GA...\n",
            "Training for GB...\n",
            "Training for GG...\n",
            "Training for GH...\n",
            "Training for GI...\n",
            "Training for GJ...\n",
            "Training for GK...\n",
            "Training for GL...\n",
            "Training for GM...\n",
            "Training for GP...\n",
            "Training for GQ...\n",
            "Training for GR...\n",
            "Training for GT...\n",
            "Training for GV...\n",
            "Training for GY...\n",
            "Training for GZ...\n",
            "Training for HA...\n",
            "Training for HK...\n",
            "Training for HO...\n",
            "Training for HQ...\n",
            "Training for HR...\n",
            "Training for HU...\n",
            "Training for IC...\n",
            "Training for ID...\n",
            "Training for IM...\n",
            "Training for IN...\n",
            "Training for IO...\n",
            "Training for IP...\n",
            "Training for IR...\n",
            "Training for IS...\n",
            "Training for IT...\n",
            "Training for IV...\n",
            "Training for IZ...\n",
            "Training for JA...\n",
            "Training for JE...\n",
            "Training for JM...\n",
            "Training for JN...\n",
            "Training for JO...\n",
            "Training for JQ...\n",
            "Training for KE...\n",
            "Training for KG...\n",
            "Training for KN...\n",
            "Training for KR...\n",
            "Training for KS...\n",
            "Training for KT...\n",
            "Training for KU...\n",
            "Training for KV...\n",
            "Training for KZ...\n",
            "Training for LA...\n",
            "Training for LE...\n",
            "Training for LG...\n",
            "Training for LH...\n",
            "Training for LI...\n",
            "Training for LO...\n",
            "Training for LQ...\n",
            "Training for LS...\n",
            "Training for LT...\n",
            "Training for LU...\n",
            "Training for LY...\n",
            "Training for MA...\n",
            "Training for MB...\n",
            "Training for MC...\n",
            "Training for MD...\n",
            "Training for MF...\n",
            "Training for MG...\n",
            "Training for MH...\n",
            "Training for MI...\n",
            "Training for MJ...\n",
            "Training for MK...\n",
            "Training for ML...\n",
            "Training for MN...\n",
            "Training for MO...\n",
            "Training for MP...\n",
            "Training for MQ...\n",
            "Training for MR...\n",
            "Training for MT...\n",
            "Training for MU...\n",
            "Training for MV...\n",
            "Training for MX...\n",
            "Training for MY...\n",
            "Training for MZ...\n",
            "Training for NC...\n",
            "Training for NE...\n",
            "Training for NF...\n",
            "Training for NG...\n",
            "Training for NH...\n",
            "Training for NI...\n",
            "Training for NL...\n",
            "Training for NO...\n",
            "Training for NP...\n",
            "Training for NR...\n",
            "Training for NS...\n",
            "Training for NT...\n",
            "Training for NU...\n",
            "Training for NZ...\n",
            "Training for OC...\n",
            "Training for OD...\n",
            "Training for OS...\n",
            "Training for PA...\n",
            "Training for PC...\n",
            "Training for PE...\n",
            "Training for PF...\n",
            "Training for PG...\n",
            "Training for PK...\n",
            "Training for PL...\n",
            "Training for PM...\n",
            "Training for PO...\n",
            "Training for PP...\n",
            "Training for PS...\n",
            "Training for PU...\n",
            "Training for QA...\n",
            "Training for RB...\n",
            "Training for RE...\n",
            "Training for RI...\n",
            "Training for RM...\n",
            "Training for RN...\n",
            "Training for RO...\n",
            "Training for RP...\n",
            "Training for RQ...\n",
            "Training for RS...\n",
            "Training for RW...\n",
            "Training for SA...\n",
            "Training for SB...\n",
            "Training for SC...\n",
            "Training for SE...\n",
            "Training for SF...\n",
            "Training for SG...\n",
            "Training for SH...\n",
            "Training for SI...\n",
            "Training for SL...\n",
            "Training for SM...\n",
            "Training for SN...\n",
            "Training for SO...\n",
            "Training for SP...\n",
            "Training for ST...\n",
            "Training for SU...\n",
            "Training for SV...\n",
            "Training for SW...\n",
            "Training for SY...\n",
            "Training for SZ...\n",
            "Training for TD...\n",
            "Training for TE...\n",
            "Training for TH...\n",
            "Training for TI...\n",
            "Training for TK...\n",
            "Training for TL...\n",
            "Training for TN...\n",
            "Training for TO...\n",
            "Training for TP...\n",
            "Training for TS...\n",
            "Training for TT...\n",
            "Training for TU...\n",
            "Training for TV...\n",
            "Training for TW...\n",
            "Training for TX...\n",
            "Training for TZ...\n",
            "Training for UG...\n",
            "Training for UK...\n",
            "Training for UP...\n",
            "Training for US...\n",
            "Training for UV...\n",
            "Training for UY...\n",
            "Training for UZ...\n",
            "Training for VC...\n",
            "Training for VE...\n",
            "Training for VI...\n",
            "Training for VM...\n",
            "Training for VQ...\n",
            "Training for VT...\n",
            "Training for WA...\n",
            "Training for WE...\n",
            "Training for WF...\n",
            "Training for WI...\n",
            "Training for WQ...\n",
            "Training for WS...\n",
            "Training for WZ...\n",
            "Training for YI...\n",
            "Training for YM...\n",
            "Training for ZA...\n",
            "Training for ZI...\n",
            "✅ timeseries_predictions.csv saved!\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive and set working dir\n",
        "drive.mount('/content/drive')\n",
        "os.chdir('/content/drive/My Drive/GbigQuth')\n",
        "# Load data\n",
        "df = pd.read_csv('pivotedmerged.csv')\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df = df[df['date'].dt.year > 2012]  # Optional filter\n",
        "\n",
        "# Save the date separately for joining later\n",
        "dates = df[['date']].copy()\n",
        "df = df.drop(columns=['date'])\n",
        "\n",
        "# Remove all-zero columns\n",
        "df = df.loc[:, (df != 0).any(axis=0)]\n",
        "\n",
        "# Placeholder to collect predictions\n",
        "prediction_records = []\n",
        "\n",
        "# Iterate over each country (i.e., each column)\n",
        "for target_country in df.columns:\n",
        "    try:\n",
        "        print(f\"Training for {target_country}...\")\n",
        "        y = df[target_country]\n",
        "        X = df.drop(columns=[target_country])\n",
        "\n",
        "        X_train, X_test, y_train, y_test, dates_train, dates_test = train_test_split(\n",
        "            X, y, dates, test_size=0.2, random_state=42\n",
        "        )\n",
        "\n",
        "        dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "        dtest = xgb.DMatrix(X_test)\n",
        "\n",
        "        params = {\n",
        "            'objective': 'reg:squarederror',\n",
        "            'eval_metric': 'rmse',\n",
        "            'max_depth': 6,\n",
        "            'eta': 0.1\n",
        "        }\n",
        "\n",
        "        model = xgb.train(params, dtrain, num_boost_round=100)\n",
        "\n",
        "        # Predict on full data\n",
        "        d_all = xgb.DMatrix(X)\n",
        "        y_pred_all = model.predict(d_all)\n",
        "\n",
        "        # Store results\n",
        "        for dt, pred in zip(dates['date'], y_pred_all):\n",
        "            prediction_records.append({\n",
        "                'date': dt,\n",
        "                'country': target_country,\n",
        "                'prediction': pred\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Skipping {target_country} due to error: {e}\")\n",
        "\n",
        "# Create final DataFrame\n",
        "df_pred = pd.DataFrame(prediction_records)\n",
        "df_pred.to_csv('timeseries_predictions.csv', index=False)\n",
        "print(\"✅ timeseries_predictions.csv saved!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dash pandas xgboost plotly\n",
        "\n",
        "import dash\n",
        "from dash import dcc, html, Input, Output\n",
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import xgboost as xgb\n",
        "\n",
        "# Load precomputed time-series predictions\n",
        "# Columns: date, country (ISO-3), prediction\n",
        "df_pred = pd.read_csv(\"timeseries_predictions.csv\")\n",
        "!pip install pycountry\n",
        "import pycountry\n",
        "\n",
        "def iso2_to_iso3(code):\n",
        "    try:\n",
        "        return pycountry.countries.get(alpha_2=code).alpha_3\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Only do this if codes are 2-letter, like \"AF\", \"US\", etc.\n",
        "df_pred['country'] = df_pred['country'].apply(iso2_to_iso3)\n",
        "df_pred = df_pred.dropna(subset=['country'])\n",
        "\n",
        "df_pred['date'] = pd.to_datetime(df_pred['date'])\n",
        "\n",
        "# Get available time points\n",
        "date_options = sorted(df_pred['date'].unique())\n",
        "\n",
        "# Start Dash app\n",
        "app = dash.Dash(__name__)\n",
        "\n",
        "app.layout = html.Div([\n",
        "    html.H2(\"Conflict/Terror Forecast Over Time\"),\n",
        "\n",
        "    dcc.Slider(\n",
        "        id='date-slider',\n",
        "        min=0,\n",
        "        max=len(date_options) - 1,\n",
        "        value=len(date_options) - 1,\n",
        "        marks={i: date.strftime('%Y-%m') for i, date in enumerate(date_options[::6])},\n",
        "        step=1\n",
        "    ),\n",
        "\n",
        "    dcc.Graph(id='map-plot'),\n",
        "\n",
        "    html.Div(id='selected-date', style={'fontSize': 20, 'marginTop': '10px'}),\n",
        "\n",
        "    html.Hr(),\n",
        "\n",
        "    dcc.Graph(id='country-timeseries'),\n",
        "])\n",
        "\n",
        "@app.callback(\n",
        "    [Output('map-plot', 'figure'),\n",
        "     Output('selected-date', 'children')],\n",
        "    Input('date-slider', 'value')\n",
        ")\n",
        "def update_map(selected_index):\n",
        "    selected_date = date_options[selected_index]\n",
        "    filtered = df_pred[df_pred['date'] == selected_date]\n",
        "\n",
        "    fig = px.choropleth(\n",
        "        filtered,\n",
        "        locations='country',\n",
        "        locationmode='ISO-3',\n",
        "        color='prediction',\n",
        "        color_continuous_scale='OrRd',\n",
        "        title=f'Predicted Intensity on {selected_date.date()}'\n",
        "    )\n",
        "    fig.update_geos(showcountries=True)\n",
        "\n",
        "    return fig, f\"Viewing Date: {selected_date.strftime('%Y-%m')}\"\n",
        "\n",
        "@app.callback(\n",
        "    Output('country-timeseries', 'figure'),\n",
        "    Input('map-plot', 'clickData')\n",
        ")\n",
        "def update_timeseries(clickData):\n",
        "    if clickData:\n",
        "        iso_code = clickData['points'][0]['location']\n",
        "    else:\n",
        "        iso_code = 'AF'  # Default\n",
        "\n",
        "    df_country = df_pred[df_pred['country'] == iso_code]\n",
        "    fig = px.line(df_country, x='date', y='prediction', title=f'{iso_code} Prediction Over Time')\n",
        "    return fig\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "usnjeV6Jvr8k",
        "outputId": "d40fed18-fa44-4530-c0bf-d5a1fdde4af9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dash in /usr/local/lib/python3.11/dist-packages (3.0.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n",
            "Requirement already satisfied: Flask<3.1,>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from dash) (3.0.3)\n",
            "Requirement already satisfied: Werkzeug<3.1 in /usr/local/lib/python3.11/dist-packages (from dash) (3.0.6)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash) (8.6.1)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash) (4.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from dash) (2.32.3)\n",
            "Requirement already satisfied: retrying in /usr/local/lib/python3.11/dist-packages (from dash) (1.3.4)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash) (1.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash) (75.2.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.14.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (3.1.6)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (8.1.8)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash) (1.9.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->dash) (2025.1.31)\n",
            "Collecting pycountry\n",
            "  Downloading pycountry-24.6.1-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading pycountry-24.6.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pycountry\n",
            "Successfully installed pycountry-24.6.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-b34f24867d27>:25: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "(async (port, path, width, height, cache, element) => {\n",
              "    if (!google.colab.kernel.accessAllowed && !cache) {\n",
              "      return;\n",
              "    }\n",
              "    element.appendChild(document.createTextNode(''));\n",
              "    const url = await google.colab.kernel.proxyPort(port, {cache});\n",
              "    const iframe = document.createElement('iframe');\n",
              "    iframe.src = new URL(path, url).toString();\n",
              "    iframe.height = height;\n",
              "    iframe.width = width;\n",
              "    iframe.style.border = 0;\n",
              "    iframe.allow = [\n",
              "        'accelerometer',\n",
              "        'autoplay',\n",
              "        'camera',\n",
              "        'clipboard-read',\n",
              "        'clipboard-write',\n",
              "        'gyroscope',\n",
              "        'magnetometer',\n",
              "        'microphone',\n",
              "        'serial',\n",
              "        'usb',\n",
              "        'xr-spatial-tracking',\n",
              "    ].join('; ');\n",
              "    element.appendChild(iframe);\n",
              "  })(8050, \"/\", \"100%\", 650, false, window.element)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}